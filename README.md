# paper_reading_classes

## Classes list

### 2017-10: First paper reading classes serise
- topic: deep learning
- objective: Understanding rescent history of deep learning
- paper list:
  - [0] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. "Deep learning." Nature 521.7553 (2015): 436-444. [pdf](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) (Three Giants' Survey)
  - [1] （管）Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18.7 (2006): 1527-1554. [pdf](http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf) (Deep Learning Eve)
  - [2] （邓）Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. "Reducing the dimensionality of data with neural networks." Science 313.5786 (2006): 504-507. [pdf](http://www.cs.toronto.edu/~hinton/science.pdf) (Milestone, Show the promise of deep learning)
  - [3] （李）Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems. 2012. [pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) (AlexNet, Deep Learning Breakthrough)
  - [4] （赵）Vincent Dumoulin and Francesco Visin. "A guide for convolution arithmetic for deep learning" [pdf](https://arxiv.org/abs/1603.07285)
  - [5] （彭）DenseNet. Densely Connected Convolutional Networks.
  - [6] （管）Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. "Speech recognition with deep recurrent neural networks." 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. [pdf](https://arxiv.org/pdf/1303.5778.pdf) (RNN)
  - [7] （李）Jaderberg, Max, et al. "Decoupled neural interfaces using synthetic gradients." arXiv preprint arXiv:1608.05343 (2016). [pdf](https://arxiv.org/pdf/1608.05343.pdf) (Innovation of Training Method,Amazing Work)
  - [8] （赵）Kenji Kawaguchi. "Deep Learning without Poor Local Minima" [pdf](https://papers.nips.cc/paper/6112-deep-learning-without-poor-local-minima.pdf) (great work on fundation of deep learning)

### Convolutional Neural Networks Architectures [by PP]
- [1] AlexNet. ImageNet Classification with Deep Convolutional Neural Networks.
- [2] VGG-Net. Very Deep Convolutional Networks for Large-Scale Image Recognition.
- [3] GooLeNet. Going Deeper with Convolutions. 
- [4] InceptionV3. Rethinking the Inception Architecture for Computer Vision.
- [5] ResNet. Deep Residual Learning for Image Recognition.
- [6] InceptionV4. Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning.
- [7] Deep Networks with Stochastic Depth.
- [8] （彭）DenseNet. Densely Connected Convolutional Networks.
- [9] Multi-Scale DenseNet. Multi-Scale Dense Convolutional Networks for Efficient Prediction.
- [10] Xception. Xception: Deep Learning with Depthwise Separable Convolutions.

  
### Theory of Deep learning papers:
  
  - [0] Hinton, Boltzmann machine related papers.[Introduction](https://en.wikipedia.org/wiki/Boltzmann_machine)
  - [1] information geometry and Boltzmann machine related papers. [Geometry and Expressive Power of Conditional Restricted Boltzmann Machines](http://www.jmlr.org/papers/volume16/montufar15b/montufar15b.pdf)
  - [2] Naftali Tishby, [Information Theory of Deep Learning.](https://www.youtube.com/watch?v=bLqJHjXihK8&feature=youtu.be)
  - [3] 中文材料[波尔兹曼机](https://deeplearning4j.org/cn/restrictedboltzmannmachine)
  - [4] 会议[Deep Learning: Theory, Algorithms, and Applications. Berlin, June 2017](https://www.youtube.com/watch?v=Vx3uN0dt8M8&list=PLJOzdkh8T5kqCNV_v1w2tapvtJDZYiohW)
  
